papers:
  - 
    layout: paper
    paper-type: article
    year: 2019
    title: "Missing traffic data imputation and pattern discovery with a Bayesian augmented tensor factorization model"
    authors: Xinyu Chen, Zhaocheng He, Yixian Chen, Yuhuan Lu, Jiawei Wang
    journal: "Transportation Research Part C: Emerging Technologies"
    doc-url: https://doi.org/10.1016/j.trc.2019.03.003
    data: http://doi.org/10.5281/zenodo.1205229
    code: https://github.com/sysuits/BATF
    slides: https://doi.org/10.5281/zenodo.2632552
    volume: 104
    pages: 66&ndash;77
    venue: journal

  - 
    layout: paper
    paper-type: article
    year: 2019
    title: "A Bayesian tensor decomposition approach for spatiotemporal traffic data imputation"
    authors: Xinyu Chen, Zhaocheng He, Lijun Sun
    journal: "Transportation Research Part C: Emerging Technologies"
    doc-url: https://doi.org/10.1016/j.trc.2018.11.003
    data: http://doi.org/10.5281/zenodo.1205229
    code: https://github.com/xinychen/transdim/blob/master/experiments/Imputation-BGCP.ipynb
    volume: 98
#     number: 3
#     article: 8
    pages: 73&ndash;84
    venue: journal

  - 
    layout: paper
    paper-type: article
    year: 2018
    title: "Spatial-temporal traffic speed patterns discovery and incomplete data recovery via SVD-combined tensor decomposition"
    authors: Xinyu Chen, Zhaocheng He, Jiawei Wang
    journal: "Transportation Research Part C: Emerging Technologies"
    doc-url: http://doi.org/10.1016/j.trc.2017.10.023
    volume: 86
    pages: 59&ndash;77
    venue: journal






#     errata: >
#       The reference for Banerjee and Lavie (2005) on p. 39 is missing. It should be:
#       <ul><li>
#       S. Banerjee and A. Lavie. METEOR: An Automatic Metric for MT Evaluation with 
#       Improved Correlation with Human Judgments. In Proceedings of the ACL 2005 
#       Workshop on Intrinsic and Extrinsic Evaulation Measures for MT and/or 
#       Summarization, 2005.
#       </li></ul>
#       Thanks to Matt Snover for pointing this out.
#       <p>There is a typo in rule S3 on page 11; the English and Chinese sides of the rule are swapped.  It should read:
#       <ul><li>
#       NPB &rarr; JJ<sub>1</sub> NPB<sub>2</sub> / NPB<sub>2</sub> JJ<sub>1</sub>
#       </li></ul>
#       Thanks to Anoop Sarkar for pointing this out.
#   - layout: paper
#     paper-type: inproceedings
#     year: 2018
#     title: "Neural networks for cross-lingual negation scope detection"
#     authors: "Federico Fancellu, Adam Lopez, and Bonnie Webber"
#     booktitle: "arXiv preprint arXiv:1810.02156"
#     doc-url: https://arxiv.org/abs/1810.02156
#     venue: working
#   - layout: paper
#     year: 2018
#     paper-type: inproceedings
#     img: inpress
#     title: A structured syntax-semantics interface for English-AMR alignment
#     authors: Ida Szubert, Adam Lopez, and Nathan Schneider
#     booktitle: Proceedings of NAACL
#     booktitle-url: http://naacl2018.org/
#     doc-url: http://aclweb.org/anthology/N18-1106
#     venue: conference
#     img: naacl2018
#     data: https://github.com/ida-szubert/amr_ud/
#     abstract: >
#       Abstract Meaning Representation (AMR) annotations are often assumed 
#       to closely mirror dependency syntax, but AMR explicitly does not 
#       require this, and the assumption has never been tested. To test it, 
#       we devise an expressive framework to align AMR graphs to dependency 
#       graphs, which we use to annotate 200 AMRs. Our annotation explains 
#       how 97% of AMR edges are evoked by words or syntax. Previously 
#       existing AMR alignment frameworks did not allow for mapping AMR onto 
#       syntax, and as a consequence they explained at most 23%. While we 
#       find that there are indeed many cases where AMR annotations closely 
#       mirror syntax, there are also pervasive differences. We use our 
#       annotations to test a baseline AMR-to-syntax aligner, finding that 
#       this task is more difficult than AMR-to-string alignment; and to 
#       pinpoint errors in an AMR parser. We make our data and code freely 
#       available for further research on AMR parsing and generation, and the 
#       relationship of AMR to syntax.
#   - layout: paper
#     paper-type: inproceedings
#     year: 2017
#     img: deplambdanot
#     title: Universal dependencies to logical forms with negation scope
#     authors: Federico Fancellu, Siva Reddy, Adam Lopez, and Bonnie Webber
#     booktitle: Proceedings of the Workshop on Computational Semantics Beyond Events and Roles
#     booktitle-url: http://www.cse.unt.edu/sembear2017/
#     doc-url: http://aclweb.org/anthology/W17-1804
#     venue: workshop
#     abstract: >
#       Many language technology applications
#       would benefit from the ability to represent
#       negation and its scope on top of widely-used
#       linguistic resources. In this paper, we
#       investigate the possibility of obtaining a
#       first-order logic representation with negation
#       scope marked using Universal Dependencies.
#       To do so, we enhance UDepLambda,
#       a framework that converts dependency
#       graphs to logical forms. The resulting
#       UDepLambda is able to handle
#       phenomena related to scope by means of
#       an higher-order type theory, relevant not
#       only to negation but also to universal quantification
#       and other complex semantic phenomena.
#       The initial conversion we did for
#       English is promising, in that one can represent
#       the scope of negation also in the presence
#       of more complex phenomena such as
#       universal quantifiers.
#   - layout: paper
#     paper-type: inproceedings
#     year: 2016
#     img: nneg
#     title: Neural networks for negation scope detection
#     authors: Federico Fancellu, Adam Lopez, and Bonnie Webber
#     booktitle: Proceedings of ACL
#     code: https://github.com/ffancellu/NegNN
#     booktitle-url: http://acl2016.org/
#     doc-url: http://www.aclweb.org/anthology/P16-1047
#     venue: conference
#     abstract: >
#       Automatic negation scope detection is a task that has been tackled 
#       using different classifiers and heuristics. Most systems are however 
#       1) highly-engineered, 2) English-specific, and 3) only tested on 
#       the same genre they were trained on. We start by addressing 1) and 2) 
#       using a neural network architecture. Results obtained on data from 
#       the *SEM2012 shared task on negation scope detection show that even a 
#       simple feed-forward neural network using word-embedding features 
#       alone, performs on par with earlier classifiers, with a 
#       bi-directional LSTM outperforming all of them. We then address 3) by 
#       means of a specially-designed synthetic test set; in doing so, we 
#       explore the problem of detecting the negation scope more in depth and 
#       show that performance suffers from genre effects and differs with the 
#       type of negation considered.
#   - layout: paper
#     paper-type: inproceedings
#     year: 2015
#     img: amrica
#     title: AMRICA&#58; an AMR Inspector for Cross-language Alignments
#     doc-url: http://www.aclweb.org/anthology/N15-3008
#     authors: Naomi Saphra and Adam Lopez
#     booktitle: NAACL-HLT Demonstrations
#     booktitle-url: http://naacl.org/naacl-hlt-2015/
#     venue: workshop
#     code: https://github.com/nsaphra/AMRICA
#     abstract: > 
#       Abstract Meaning Representation (AMR), an
#       annotation scheme for natural language semantics,
#       has drawn attention for its simplicity
#       and representational power. Because AMR
#       annotations are not designed for human readability,
#       we present AMRICA, a visual aid for
#       exploration of AMR annotations. AMRICA
#       can visualize an AMR or the difference between
#       two AMRs to help users diagnose interannotator
#       disagreement or errors from an
#       AMR parser. AMRICA can also automatically
#       align and visualize the AMRs of a sentence
#       and its translation in a parallel text. We
#       believe AMRICA will simplify and streamline
#       exploratory research on cross-lingual AMR
#       corpora.
#   - layout: paper
#     selected: no
#     paper-type: article 
#     year: 2015
#     img: hiero-gpu
#     title: Gappy pattern matching on GPUs for on-demand extraction of hierarchical translation grammars
#     doc-url: http://aclweb.org/anthology/Q15-1007
#     authors: Hua He, Jimmy Lin, and Adam Lopez
#     journal: Transactions of the ACL
#     journal-url: https://tacl2013.cs.columbia.edu/ojs/index.php/tacl
#     code: http://hohocode.github.io/cgx/
#     volume: 3
#     venue: journal
#     abstract: >
#       Grammars for machine translation can
#       be materialized on demand by finding source phrases in an
#       indexed parallel corpus and extracting their translations.
#       This approach is limited in practical applications
#       by the computational expense of online lookup and extraction.
#       For <em>phrase-based</em> models, recent work has shown that on-demand grammar extraction
#       can be greatly accelerated by parallelization on general purpose graphics processing
#       units (GPUs), but these algorithms do not
#       work for <em>hierarchical</em>, which require matching patterns that contain gaps.
#       We address this limitation by presenting a novel
#       GPU algorithm for on-demand hierarchical grammar
#       extraction that is at least an order of magnitude faster than
#       a comparable CPU algorithm when processing large batches of sentences.
#       In terms of end-to-end translation, with decoding on the CPU, we increase
#       throughput by roughly two thirds on a standard MT evaluation dataset.
#       The GPU necessary to achieve these improvements increases the cost of a server by about a third.
#       We believe that GPU-based extraction of hierarchical grammars
#       is an attractive proposition, particularly for MT applications
#       that demand high throughput.
#   - layout: paper
#     paper-type: inproceedings
#     selected: no
#     year: 2013
#     img: iwslt2013
#     title: General lattice decoding for improved speech-to-text translation with the Fisher and Callhome Spanish-English Speech Translation Corpus 
#     authors: Matt Post, Gaurav Kumar, Adam Lopez, Damianos Karakos, Chris Callison-Burch, and Sanjeev Khudanpur
#     booktitle: Proceedings of IWSLT
#     booktitle-url: http://www.iwslt2013.org/
#     doc-url: https://matt.waypost.net/papers/post-etal-2013-improved.revised-2020-03-10.pdf
#     data: https://catalog.ldc.upenn.edu/ldc2014t23
#     venue: workshop
#     abstract: >
#       <p>Research into the translation of the output of automatic speech 
#       recognition (ASR) systems is hindered by the dearth of datasets 
#       developed for that explicit purpose. For Spanish-English translation, 
#       in particular, most parallel data available exists only in vastly 
#       different domains and registers. In order to support research on 
#       cross-lingual speech applications, we introduce the Fisher and 
#       Callhome Spanish-English Speech Translation Corpus, supplementing 
#       existing LDC audio and transcripts with (a) ASR 1-best, lattice, 
#       and oracle output produced by the Kaldi recognition system and 
#       (b) English translations obtained on Amazon’s Mechanical Turk. 
#       The result is a four-way parallel dataset of Spanish audio, 
#       transcriptions, ASR lattices, and English translations of 
#       approximately 38 hours of speech, with defined training, development, 
#       and held-out test sets.</p>
#       <p>We conduct baseline machine translation experiments using models 
#       trained on the provided training data, and validate the dataset by 
#       corroborating a number of known results in the field, including the 
#       utility of in-domain (information, conversational) training data, 
#       increased performance translating lattices (instead of recognizer 
#       1-best output), and the relationship between word error rate and 
#       BLEU score.</p>
#   - layout: paper
#     paper-type: inproceedings
#     selected: no
#     year: 2013
#     img: 20yearsofbitext
#     title: Beyond bitext&#58; Five open problems in machine translation
#     doc-url: https://mjpost.github.io/papers/lopez-post-bitext13.pdf
#     authors: with Matt Post
#     booktitle: Twenty Years of Bitext
#     booktitle-url: https://sites.google.com/site/20yearsofbitext/
#     abstract: >
#       In twenty years, the machine translation (MT)
#       research community has learned a great deal
#       about problems that can be solved with bitext. Yet for many potential
#       MT uses, there is little if any available bitext.
#       In the next twenty years, these uses will become
#       increasingly important, and the research community
#       must marshal its resources to solve
#       the new problems that they present. Specifically, we must assemble
#       large numbers of <i>small</i> bitexts for testing systems,
#       rather than small numbers of <i>large</i> bitexts
#       for training them. Small bitexts won't solve the new problems
#       alone, but they will help the research community identify 
#       the problems that need solving.
#   -
#     layout: paper
#     paper-type: inproceedings
#     selected: no
#     year: 2013
#     img: acl2013
#     title: Dirt cheap Web-scale parallel text from the Common Crawl
#     authors: Jason Smith, Herve Saint-Amand, Magdalena Plamada, Philipp Koehn, Chris Callison-Burch and Adam Lopez
#     booktitle: Proceedings of ACL
#     doc-url: http://aclweb.org/anthology/P13-1135
#     booktitle-url: http://acl2013.org/site/
#     code: https://github.com/jrs026/CommonCrawlMiner
#     venue: conference
#     abstract: >
#       Parallel text is the fuel that drives modern
#       machine translation systems. The Web is a
#       comprehensive source of preexisting parallel text, but crawling the entire web is
#       impossible for all but the largest companies. We bring web-scale parallel text to
#       the masses by mining the Common Crawl,
#       a public Web crawl hosted on Amazon’s
#       Elastic Cloud. Starting from nothing more
#       than a set of common two-letter language
#       codes, our open-source extension of the
#       STRAND algorithm mined 32 terabytes of
#       the crawl in just under a day, at a cost of
#       about $500. Our large-scale experiment
#       uncovers large amounts of parallel text in
#       dozens of language pairs across a variety
#       of domains and genres, some previously
#       unavailable in curated datasets. Even with
#       minimal cleaning and ﬁltering, the resulting data boosts translation performance
#       across the board for ﬁve different language
#       pairs in the news domain, and on open domain test sets we see improvements of up
#       to 5 BLEU. We make our code and data
#       available for other researchers seeking to
#       mine this rich new data resource.
#   -
#     layout: paper
#     selected: no
#     paper-type: inproceedings
#     year: 2013
#     title: Massively parallel suffix array queries and on-demand phrase extraction for statistical machine translation using GPUs
#     authors: Hua He, Jimmy Lin, and Adam Lopez
#     doc-url: http://aclweb.org/anthology/N13-1033
#     img: naacl2013
#     booktitle: Proceedings of NAACL HLT
#     booktitle-url: http://naacl2013.naacl.org/
#     venue: conference
#     abstract: >
#       Translation models can be scaled to large corpora and arbitrarily-long
#       phrases by looking up translations of source phrases on the fly in
#       an indexed parallel text. However, this is impractical because
#       on-demand extraction of phrase tables is a major computational
#       bottleneck. We solve this problem by developing novel algorithms for
#       general purpose graphics processing units (GPUs), which enable suffix
#       array queries for phrase lookup and phrase extractions to be massively
#       parallelized. Our open-source implementation improves the speed of a
#       highly-optimized, state-of-the-art serial CPU-based implementation by
#       at least an order of magnitude. In a Chinese-English translation task, our
#       GPU implementation extracts translation tables from
#       approximately 100 million words of parallel text in less than 30
#       milliseconds.
#   -
#     layout: paper
#     selected: no
#     paper-type: article 
#     year: 2013
#     title: Learning to translate with products of novices&#58; a suite of open-ended challenge problems for teaching MT
#     authors: With Matt Post, Chris Callison-Burch, Jonathan Weese, Juri Ganitkevitch, Narges Ahmidi, Olivia Buzek, Leah Hanson, Beenish Jamil, Matthias Lee, Ya-Ting Lin, Henry Pao, Fatima Rivera, Leili Shahriyari, Debu Sinha, Adam Teichert, Stephen Wampler, Michael Weinberger, Daguang Xu, Lin Yang, and Shang Zhao
#     doc-url: http://aclweb.org/anthology/Q13-1014
#     code: http://alopez.github.io/dreamt/
#     img: tacl2013
#     journal: Transactions of the ACL
#     journal-url: https://tacl2013.cs.columbia.edu/ojs/index.php/tacl/index
#     volume: 1
#     pages: 165&ndash;178
#     venue: journal
#     abstract: > 
#       Machine translation (MT) draws from several different disciplines, making 
#       it a complex subject to teach. There are excellent pedagogical texts, but 
#       problems in MT and current algorithms for solving them are best learned by 
#       doing. As a centerpiece of our MT course, we devised a series of open-ended 
#       challenges for students in which the goal was to improve performance on 
#       carefully constrained instances of four key MT tasks: alignment, decoding, 
#       evaluation, and reranking. Students brought a diverse set of techniques to 
#       the problems, including some novel solutions which performed remarkably well. 
#       A surprising and exciting outcome was that student solutions or their 
#       combinations fared competitively on some tasks, demonstrating that even 
#       newcomers to the field can help improve the state-of-the-art on hard NLP 
#       problems while simultaneously learning a great deal. The problems, baseline 
#       code, and results are freely available.
#   -
#     layout: paper
#     paper-type: inproceedings
#     year: 2012
#     title: Putting human assessments of machine translation systems in order
#     doc-url: http://aclweb.org/anthology/W12-3101
#     booktitle: Proceedings of WMT
#     booktitle-url: http://www.statmt.org/wmt12/
#     code: https://github.com/alopez/wmt-ranking
#     img: wmt2012
#     venue: workshop
#     abstract: >
#       Human assessment is often considered the gold standard in evaluation of 
#       translation systems. But in order for the evaluation to be meaningful, 
#       the rankings obtained from human assessment must be consistent and 
#       repeatable, and recent analysis by <a href="http://aclweb.org/anthology-new/W/W11/W11-2101.pdf">Bojar et al. (2011)</a> raised 
#       several concerns about the rankings derived from human assessments of 
#       English-Czech translation systems in the 2010 Workshop on Machine Translation.
#       We extend their analysis to <i>all</i> of the ranking tasks from 2010 and 
#       2011, and show through an extension of their reasoning that the ranking is 
#       naturally cast as an instance of finding the minimum feedback arc set in a 
#       tournament, a well-known NP-complete problem. All instances of this problem 
#       in the workshop data are efficiently solvable, but in some cases the rankings 
#       it produces are surprisingly different from the ones previously published. 
#       This leads to strong caveats and recommendations for both producers and 
#       consumers of these rankings.
#   -
#     layout: paper
#     paper-type: inproceedings
#     year: 2012
#     title: Using categorial grammar to label translation rules
#     doc-url: http://www.aclweb.org/anthology/W12-3127
#     authors: Jonathan Weese, Chris Callison-Burch and Adam Lopez
#     booktitle: Proceedings of WMT
#     booktitle-url: http://www.statmt.org/wmt12/
#     img: wmt-ccg2012
#     venue: workshop
#     abstract: >
#       Adding syntactic labels to synchronous context-free translation rules can
#       improve performance, but labeling with phrase structure constituents, as in
#       GHKM (Galley et al., 2004), excludes potentially useful translation rules. 
#       SAMT (Zollmann and Venugopal, 2006) introduces heuristics to create new
#       non-constituent labels, but these heuristics introduce many complex labels and
#       tend to add rarely-applicable rules to the translation grammar.        We
#       introduce a new labeling scheme based on categorial grammar, which allows
#       syntactic labeling of many rules with a minimal, well-motivated label set. We
#       show that our labeling scheme performs comparably to SAMT on an Urdu–English
#       translation task, yet the label set is an order of magnitude smaller, and
#       translation is twice as fast.
#   -
#     layout: paper
#     paper-type: inproceedings
#     selected: no
#     year: 2011
#     authors: Michael Auli and Adam Lopez
#     title: Training a log-linear parser with loss functions via softmax-margin
#     doc-url: http://aclweb.org/anthology/D11-1031
#     img: emnlp2011
#     booktitle: Proceedings of EMNLP
#     booktitle-url: http://conferences.inf.ed.ac.uk/emnlp2011/
#     venue: conference
#     abstract: >
#       Log-linear parsing models are often trained by optimizing 
#       likelihood, but we would prefer to optimize for a task-specific metric like F-measure.
#       Softmax-margin is a convex objective for such models that minimizes a bound on 
#       expected risk for a given loss function, but its naïve application requires the loss 
#       to decompose over the predicted structure, which is not true of F-measure.
#       We use softmax-margin to optimize a log-linear CCG parser for a variety of loss functions, and
#       demonstrate a novel dynamic programming algorithm that enables us to use it with
#       F-measure, leading to substantial gains in accuracy on CCGBank.  When we embed our
#       loss-trained parser into a larger model that includes supertagging features
#       incorporated via belief propagation, we obtain further improvements and achieve 
#       a labelled/unlabelled dependency 
#       F-measure of 89.3%/94.0% on gold part-of-speech tags,
#       and 87.2%/92.8% on automatic part-of-speech
#       tags, the best reported results for this task.
#   -
#     layout: paper
#     paper-type: inproceedings
#     year: 2011
#     authors: Jonathan Weese, Juri Ganitkevitch, Chris Callison-Burch, Matt Post and Adam Lopez
#     title: Joshua 3.0&#58; Syntax-based machine translation with the Thrax grammar extractor
#     doc-url: http://aclweb.org/anthology/W11-2160
#     img: wmt2011
#     booktitle: Proceedings of WMT
#     booktitle-url: http://statmt.org/wmt11/
#     venue: workshop
#     abstract: >
#       We present progress on Joshua, an open-source decoder for hierarchical and 
#       syntax-based machine translation. The main focus is describing Thrax, a 
#       ﬂexible, open source synchronous context-free grammar extractor. Thrax 
#       extracts both hierarchical (Chiang, 2007) and syntax-augmented machine
#       translation (Zollmann and Venugopal, 2006) grammars. It is built on Apache 
#       Hadoop for efficient distributed performance, and can easily be extended 
#       with support for new grammars, feature functions, and output formats.
#   -
#     layout: paper
#     paper-type: inproceedings
#     year: 2011
#     authors: Michael Auli and Adam Lopez
#     title: A comparison of loopy belief propagation and dual decomposition for integrated CCG supertagging and parsing
#     doc-url: http://aclweb.org/anthology/P11-1048
#     img: acl-bp2011
#     booktitle: Proceedings of ACL 
#     booktitle-url: http://www.acl2011.org/
#     venue: conference
#     abstract: >
#       Via an oracle experiment, we show that the upper bound on accuracy of a CCG 
#       parser is significantly lowered when its search space is pruned using a 
#       supertagger, though the supertagger also prunes many bad parses.  Inspired by 
#       this analysis, we design a single model with both supertagging and parsing 
#       features, rather than separating them into distinct models chained together 
#       in a pipeline.  To overcome the resulting increase in complexity, we 
#       experiment with both belief propagation and dual decomposition approaches to 
#       inference, the first empirical comparison of these algorithms that we are 
#       aware of on a structured natural language processing problem.  On CCGbank we 
#       achieve a labelled dependency F-measure of 88.8% on gold POS tags, and 
#       86.7% on automatic part-of-speech tags, the best reported results for this 
#       task.
#   -
#     layout: paper
#     paper-type: inproceedings
#     year: 2011
#     authors: Michael Auli and Adam Lopez
#     title: Efficient CCG parsing&#58; A* versus adaptive supertagging
#     doc-url: http://aclweb.org/anthology/P11-1158
#     img: acl-astar2011
#     booktitle: Proceedings of ACL 
#     booktitle-url: http://www.acl2011.org/
#     venue: conference
#     abstract: >
#       We present a systematic comparison and combination of two orthogonal techniques for efficient 
#       parsing of Combinatory Categorial Grammar (CCG).  First we consider adaptive supertagging, a 
#       widely used approximate search technique that prunes most lexical categories from the parser's 
#       search space using a separate sequence model.  Next we consider several variants on A*, a 
#       classic exact search technique which to our knowledge has not been applied to more expressive 
#       grammar formalisms like CCG.  In addition to standard hardware-independent measures of parser 
#       effort we also present what we believe is the first evaluation of A* parsing on the more 
#       realistic but more stringent metric of CPU time.  By itself, A* substantially reduces parser 
#       effort as measured by the number of edges considered during parsing, but we show that for CCG 
#       this does not always correspond to improvements in CPU time over a CKY baseline.  Combining A* 
#       with adaptive supertagging decreases CPU time by 15% for our best model.
#   -
#     layout: paper
#     year: 2010
#     paper-type: techreport 
#     authors: Phil Blunsom, Chris Callison-Burch, Trevor Cohn, Chris Dyer, Jonathan Graehl, Adam Lopez, Jan Botha, Vladimir Eidelman, ThuyLinh Nguyen, Ziyuan Wang, Jonathan Weese, Olivia Buzek, and Desai Chen
#     title: Final report of the 2010 CLSP workshop on models for synchronous grammar induction
#     img: clsp2010
#     doc-url: http://www.clsp.jhu.edu/workshops/archive/ws10/groups/models-of-synchronous-grammar-induction-for-smt/
#     abstract: >
#       The last decade of research in Statistical Machine Translation (SMT) 
#       has seen rapid progress. The most successful methods have been based 
#       on synchronous context free grammars (SCFGs), which encode 
#       translational equivalences and license reordering between tokens in 
#       the source and target languages. Yet, while closely related language 
#       pairs can be translated with a high degree of precision now, the 
#       result for distant pairs is far from acceptable. In theory, however, 
#       the right SCFG is capable of handling most, if not all, structurally
#       divergent language pairs. So we propose to focus on the crucial 
#       practical aspects of acquiring such SCFGs from bilingual text. We will
#       take the pragmatic approach of starting with existing algorithms for 
#       inducing <i>unlabelled</i> SCFGs (e.g. the popular Hiero model), and 
#       then using state-of-the-art hierarchical non-parametric Bayesian 
#       methods to iteratively refine the syntactic constituents used in the 
#       translation rules of the grammar, hoping to approach, in an 
#       unsupervised manner, SCFGs learned from massive quantities of manually
#       tree-banked parallel text. 
#   -
#     layout: paper
#     paper-type: article
#     year: 2010
#     authors: Abhishek Arun, Barry Haddow, Philipp Koehn, Adam Lopez, Phil Blunsom, and Chris Dyer
#     title: Monte Carlo techniques for phrase-based translation
#     doc-url: http://link.springer.com/article/10.1007%2Fs10590-010-9080-7
#     journal: Machine Translation
#     journal-url: http://www.springer.com/computer/ai/journal/10590
#     img: mtj2010
#     volume: 24
#     number: 2
#     venue: journal
#     abstract: >
#       Recent advances in statistical machine translation have used approximate beam search for NP-complete inference within probabilistic translation models. We present an alternative approach of sampling from the posterior distribution defined by a translation model. We define a novel Gibbs sampler for sampling translations given a source sentence and show that it effectively explores this posterior distribution. In doing so we overcome the limitations of heuristic beam search and obtain theoretically sound solutions to inference problems such as finding the maximum probability translation and minimum risk training and decoding. 
#   -
#     layout: paper
#     paper-type: inproceedings
#     year: 2010
#     authors: Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonny Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vlad Eidelman, and Philip Resnik
#     title: cdec&#58; A decoder, alignment, and learning framework for finite-state and context-free translation models
#     pages: 7&ndash;12
#     booktitle: Proceedings of ACL (Demonstration track)
#     booktitle-url: http://www.acl2010.org/
#     img: cdec2010
#     code: https://github.com/redpony/cdec
#     doc-url: http://aclweb.org/anthology/P10-4002
#     venue: workshop
#     abstract: >
#       We present cdec, an open source framework for decoding, aligning with, and 
#       training a number of statistical machine 
#       translation models, including word-based 
#       models, phrase-based models, and models 
#       based on synchronous context-free grammars. Using a single uniﬁed internal 
#       representation for translation forests, the 
#       decoder strictly separates model-speciﬁc 
#       translation logic from general rescoring, 
#       pruning, and inference algorithms. From 
#       this uniﬁed representation, the decoder can 
#       extract not only the 1- or k-best translations, but also alignments to a reference, 
#       or the quantities necessary to drive discriminative training using gradient-based 
#       or gradient-free optimization techniques. 
#       Its efficient C++ implementation means 
#       that memory use and runtime performance 
#       are signiﬁcantly better than comparable 
#       decoders.
#   -
#     layout: paper
#     paper-type: inproceedings
#     year: 2009
#     authors: Hieu Hoang, Philipp Koehn, and Adam Lopez
#     title: A unified framework for phrase-based, hierarchical, and syntax-based statistical machine translation
#     booktitle: Proceedings of IWSLT
#     booktitle-url: http://mt-archive.info/IWSLT-2009-TOC.htm
#     img: iwslt2009
#     doc-url: http://mt-archive.info/IWSLT-2009-Hoang.pdf
#     code: https://github.com/moses-smt/mosesdecoder
#     venue: workshop
#     abstract: >
#       Despite many differences between phrase-based, hierarchical, and syntax-based translation models, their training and testing pipelines are strikingly similar.  Drawing on this fact, we extend the Moses toolkit to implement hierarchical and syntactic models, making it the first open source toolkit with end-to-end support for all three of these popular models in a single package.  This extension substantially lowers the barrier to entry for machine translation research across multiple models.
#   -
#     layout: paper
#     paper-type: inproceedings
#     year: 2009
#     authors: Abhishek Arun, Chris Dyer, Barry Haddow, Phil Blunsom, Adam Lopez, and Philipp Koehn
#     title: Monte Carlo inference and maximization for phrase-based translation
#     doc-url: http://aclweb.org/anthology/W09-1114
#     booktitle: Proceedings of CoNLL
#     booktitle-url: http://www.cnts.ua.ac.be/conll2009/
#     img: conll2009
#     venue: conference
#     abstract: >
#       Recent advances in statistical machine translation have used beam search for 
#       approximate NP-complete inference within probabilistic translation models.
#       We present an alternative approach of sampling from the posterior distribution 
#       defined by a translation model.  We define a novel Gibbs sampler for sampling 
#       translations given a source sentence and show that it effectively explores this 
#       posterior distribution.  In doing so we overcome the limitations of heuristic 
#       beam search and obtain theoretically sound solutions to inference problems such 
#       as finding the maximum probability translation and minimum expected risk training 
#       and decoding.
#   -
#     layout: paper
#     paper-type: dissertation 
#     year: 2008
#     title: Machine translation by pattern matching
#     institution: University of Maryland
#     doc-url: papers/adam.lopez.dissertation.pdf
#     img: diss2008
#     slides: http://www.cs.jhu.edu/~alopez/talks/dissertation_defense.pdf
#     latex: https://github.com/alopez/dissertation
#     abstract: >
#       <p>The best systems for machine translation of natural language are based on statistical models learned from data.  Conventional representation of a statistical translation model requires substantial offline computation and representation in main memory.  Therefore, the principal bottlenecks to the amount of data we can exploit and the complexity of models we can use are available memory and CPU time, and current state of the art already pushes these limits.  With data size and model complexity continually increasing, a scalable solution to this problem is central to future improvement.</p>
      
#       <p>Callison-Burch et al. (2005) and Zhang and Vogel (2005) proposed a solution that we call "translation by pattern matching", which we bring to fruition in this dissertation.  The training data itself serves as a proxy to the model; rules and parameters are computed on demand.  It achieves our desiderata of minimal offline computation and compact representation, but is dependent on fast pattern matching algorithms on text.  They demonstrated its application to a common model based on the translation of contiguous substrings, but leave some open problems.  Among these is a question: can this approach match the performance of conventional methods despite unavoidable differences that it induces in the model?  We show how to answer this question affirmatively.</p>
      
#       <p>The main open problem we address is much harder.  Many translation models are based on the translation of discontiguous substrings.  The best pattern matching algorithm for these models is much too slow, taking several minutes per sentence.  We develop new algorithms that reduce empirical computation time by two orders of magnitude for these models, making translation by pattern matching widely applicable.  We use these algorithms to build a model that is two orders of magnitude larger than the current state of the art and substantially outperforms a strong competitor in Chinese-English translation.  We show that a conventional representation of this model would be impractical.  Our experiments shed light on some interesting properties of the underlying model.  The dissertation also includes the most comprehensive contemporary survey of statistical machine translation.</p>
#   -
#     layout: paper
#     year: 2006
#     paper-type: inproceedings
#     authors: With Philip Resnik
#     title: Word-based alignment, phrase-based translation&#58; What's the link?
#     pages: 90&ndash;99
#     booktitle: Proceedings of AMTA
#     booktitle-url: http://amta2006.amtaweb.org/index.htm
#     doc-url: http://www.mt-archive.info/AMTA-2006-Lopez.pdf
#     slides: http://www.cs.jhu.edu/~alopez/talks/amta_2006.pdf
#     img: amta2006
#     venue: conference
#     abstract: >
#       State-of-the-art statistical machine translation is 
#       based on alignments between <i>phrases</i>&mdash;sequences of words 
#       in the source and target sentences.  The learning step in these 
#       systems often relies on alignments between <i>words</i>.  
#       It is often assumed that the quality of this word alignment is 
#       critical for translation. However, recent results suggest that
#       the relationship between alignment quality and translation quality
#       is weaker than previously thought.  We investigate this 
#       question directly, comparing the impact of high-quality 
#       alignments with a carefully constructed set of degraded 
#       alignments.  In order to tease apart various interactions, 
#       we report experiments investigating the impact of alignments 
#       on different aspects of the system.  Our results confirm a weak 
#       correlation, but they also illustrate that more data and better 
#       feature engineering may be more beneficial than better alignment.
#   -
#     layout: paper
#     paper-type: inproceedings
#     year: 2002
#     authors: With Michael Nossal, Rebecca Hwa,  and Philip Resnik
#     title: Word-level alignment for multilingual resource acquisition
#     pages: 34&ndash;42
#     booktitle: Proceedings of the LREC Workshop on Linguistic Knowledge Acquisition and Representation&mdash;Bootstrapping Annotated Language Data
#     booktitle-url: http://www.lrec-conf.org/lrec2002/lrec/wksh/Bootstrapping.html
#     doc-url: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.135.7331&rep=rep1&type=pdf
#     slides: http://www.cs.jhu.edu/~alopez/talks/lrec02-slides.pdf
#     img: lrec2002
#     venue: workshop
#     abstract: >
#       We present a simple, one-pass word alignment algorithm for parallel text. Our algorithm utilizes synchronous parsing and takes advantage 
#       of existing syntactic annotations. In our experiments the performance of this model is comparable to more complicated iterative methods. 
#       We discuss the challenges and potential beneﬁts of using this model to train syntactic parsers for new languages.
